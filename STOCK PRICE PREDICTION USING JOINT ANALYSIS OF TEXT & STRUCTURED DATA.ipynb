{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\ANURAG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ANURAG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\ANURAG\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from textblob import TextBlob\n",
    "nltk.download('gutenberg') #needed to access the raw text of a book\n",
    "nltk.download('punkt') #needed to tokenize sentences\n",
    "nltk.download('vader_lexicon') #NLTK's vader tool relies on a sentiment lexicon!\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from pandas.core import describe\n",
    "from numpy.ma import count\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install textblob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into dataframes\n",
    "price_df = pd.read_excel('Project 02 - Data.xlsx', sheet_name=0)\n",
    "tweets_df = pd.read_excel('Project 02 - Data.xlsx', sheet_name=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>open_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>moving_average_5_day</th>\n",
       "      <th>moving_average_10_day</th>\n",
       "      <th>moving_average_50_day</th>\n",
       "      <th>moving_average_200_day</th>\n",
       "      <th>volume</th>\n",
       "      <th>next_day_close_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.300000e+03</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>650.500000</td>\n",
       "      <td>51.764592</td>\n",
       "      <td>52.318354</td>\n",
       "      <td>51.232192</td>\n",
       "      <td>51.604431</td>\n",
       "      <td>51.469623</td>\n",
       "      <td>50.392154</td>\n",
       "      <td>47.170069</td>\n",
       "      <td>2.325961e+06</td>\n",
       "      <td>42.265560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>375.421985</td>\n",
       "      <td>21.392828</td>\n",
       "      <td>21.626325</td>\n",
       "      <td>21.194475</td>\n",
       "      <td>21.167761</td>\n",
       "      <td>20.969752</td>\n",
       "      <td>19.489467</td>\n",
       "      <td>14.551042</td>\n",
       "      <td>1.636736e+06</td>\n",
       "      <td>9.833662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.630000</td>\n",
       "      <td>27.930000</td>\n",
       "      <td>26.710000</td>\n",
       "      <td>27.940000</td>\n",
       "      <td>28.300000</td>\n",
       "      <td>29.560000</td>\n",
       "      <td>30.980000</td>\n",
       "      <td>6.438000e+05</td>\n",
       "      <td>27.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>325.750000</td>\n",
       "      <td>37.810000</td>\n",
       "      <td>38.175000</td>\n",
       "      <td>37.440000</td>\n",
       "      <td>37.870000</td>\n",
       "      <td>37.847500</td>\n",
       "      <td>38.687500</td>\n",
       "      <td>37.965000</td>\n",
       "      <td>1.474500e+06</td>\n",
       "      <td>36.537500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>650.500000</td>\n",
       "      <td>43.115000</td>\n",
       "      <td>43.575000</td>\n",
       "      <td>42.820000</td>\n",
       "      <td>43.030000</td>\n",
       "      <td>42.890000</td>\n",
       "      <td>42.540000</td>\n",
       "      <td>42.355000</td>\n",
       "      <td>1.940300e+06</td>\n",
       "      <td>40.175000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>975.250000</td>\n",
       "      <td>61.732500</td>\n",
       "      <td>62.525000</td>\n",
       "      <td>61.075000</td>\n",
       "      <td>61.332500</td>\n",
       "      <td>61.285000</td>\n",
       "      <td>60.010000</td>\n",
       "      <td>54.982500</td>\n",
       "      <td>2.696550e+06</td>\n",
       "      <td>45.520000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1300.000000</td>\n",
       "      <td>117.510000</td>\n",
       "      <td>117.660000</td>\n",
       "      <td>116.570000</td>\n",
       "      <td>115.490000</td>\n",
       "      <td>114.070000</td>\n",
       "      <td>107.120000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>2.078650e+07</td>\n",
       "      <td>71.070000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               day   open_price   high_price    low_price  \\\n",
       "count  1300.000000  1300.000000  1300.000000  1300.000000   \n",
       "mean    650.500000    51.764592    52.318354    51.232192   \n",
       "std     375.421985    21.392828    21.626325    21.194475   \n",
       "min       1.000000    27.630000    27.930000    26.710000   \n",
       "25%     325.750000    37.810000    38.175000    37.440000   \n",
       "50%     650.500000    43.115000    43.575000    42.820000   \n",
       "75%     975.250000    61.732500    62.525000    61.075000   \n",
       "max    1300.000000   117.510000   117.660000   116.570000   \n",
       "\n",
       "       moving_average_5_day  moving_average_10_day  moving_average_50_day  \\\n",
       "count           1300.000000            1300.000000            1300.000000   \n",
       "mean              51.604431              51.469623              50.392154   \n",
       "std               21.167761              20.969752              19.489467   \n",
       "min               27.940000              28.300000              29.560000   \n",
       "25%               37.870000              37.847500              38.687500   \n",
       "50%               43.030000              42.890000              42.540000   \n",
       "75%               61.332500              61.285000              60.010000   \n",
       "max              115.490000             114.070000             107.120000   \n",
       "\n",
       "       moving_average_200_day        volume  next_day_close_price  \n",
       "count             1300.000000  1.300000e+03           1000.000000  \n",
       "mean                47.170069  2.325961e+06             42.265560  \n",
       "std                 14.551042  1.636736e+06              9.833662  \n",
       "min                 30.980000  6.438000e+05             27.600000  \n",
       "25%                 37.965000  1.474500e+06             36.537500  \n",
       "50%                 42.355000  1.940300e+06             40.175000  \n",
       "75%                 54.982500  2.696550e+06             45.520000  \n",
       "max                 94.500000  2.078650e+07             71.070000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first few rows of price(Numerical Data)\n",
    "price_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the first few rows of tweets\n",
    "tweets_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a function to clean the tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to clean the tweets \n",
    "def clean_tweets(tweet):\n",
    "    if isinstance(tweet, str):\n",
    "        #remove all underscores from the text\n",
    "        cleaned_tweet = re.sub(r'\\_', ' ', tweet)\n",
    "        # Remove special characters and symbols\n",
    "        cleaned_tweet = re.sub(r\"[^\\w\\s]\", \"\", cleaned_tweet)\n",
    "        #remove any excess whitespace\n",
    "        cleaned_tweet = re.sub(r'\\s+',' ', cleaned_tweet).strip()\n",
    "        return cleaned_tweet\n",
    "    else:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         day                                              tweet  \\\n",
      "0          1  #Dan ($Dan) Doubles Down on Healthy, Eco-Frien...   \n",
      "1          1  RT @DvdndDiplomats: Bert's X Always Buy stocks...   \n",
      "2          1          $Dan Alert From our Stock News Alerts App   \n",
      "3          1  X NEW Stocks at #FusionIQ with Master Scores >...   \n",
      "4          1  #AmazonPrime creates a captive audience, so \"b...   \n",
      "...      ...                                                ...   \n",
      "100762  1313                              $Dan approaching ATHs   \n",
      "100763  1313  Top X Consumer Defensive stocks with market ca...   \n",
      "100764  1313  52-Week High Alert: Trading todays movement in...   \n",
      "100765  1313  $Dan MKM Partners analyst Bill Kirk maintains ...   \n",
      "100766  1313  Some tickers Im watching tmmr, Lately Ive been...   \n",
      "\n",
      "                                           cleaned_tweets  \n",
      "0       Dan Dan Doubles Down on Healthy EcoFriendly Pr...  \n",
      "1       RT DvdndDiplomats Berts X Always Buy stocks Da...  \n",
      "2                Dan Alert From our Stock News Alerts App  \n",
      "3       X NEW Stocks at FusionIQ with Master Scores 70...  \n",
      "4       AmazonPrime creates a captive audience so buyi...  \n",
      "...                                                   ...  \n",
      "100762                               Dan approaching ATHs  \n",
      "100763  Top X Consumer Defensive stocks with market ca...  \n",
      "100764  52Week High Alert Trading todays movement in D...  \n",
      "100765  Dan MKM Partners analyst Bill Kirk maintains D...  \n",
      "100766  Some tickers Im watching tmmr Lately Ive been ...  \n",
      "\n",
      "[100767 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "tweets_df['cleaned_tweets'] = tweets_df.tweet.apply(clean_tweets)\n",
    "print(tweets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_tweets = [] \n",
    "#cleaned_tweets= tweets_df['cleaned_tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaned_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating polarity and subjectivity scores for each tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = []\n",
    "subjectivities = []\n",
    "\n",
    "#get polarity and subjectivity scores for each sentence\n",
    "for sentence in cleaned_tweets:\n",
    "  #the str() function is used to ensure that the input value is a string\n",
    "  blob = TextBlob(str(sentence)) \n",
    "  #get polarity and subjectivity scores\n",
    "  polarity, subjectivity = blob.polarity, blob.subjectivity\n",
    "  print('sentence: \"{}\", polarity: {:.3f}, subjectivity: {:.3f}'.format(sentence, polarity, subjectivity))\n",
    "  polarities.append(polarity)\n",
    "  subjectivities.append(subjectivity)\n",
    "\n",
    "#calculate and display average polarity and subjectivity scores for all sentences\n",
    "print('average polarity: {:.3f}'.format(np.mean(polarities)))\n",
    "print('average subjectivity: {:.3f}'.format(np.mean(subjectivities)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "#Calculating the polarity and aggregating with respect to day\n",
    "for index,row in tweets_df.iterrows():\n",
    "    day = row['day']\n",
    "    tweet = row['cleaned_tweets']\n",
    "    #the str() function is used to ensure that the input value is a string\n",
    "    blob = TextBlob(str(tweet))\n",
    "    #get polarity and subjectivity scores\n",
    "    polarity, subjectivity = blob.polarity, blob.subjectivity\n",
    "    if day not in scores:\n",
    "        scores[day] = {'polarity':[],'subjectivity':[]}\n",
    "    scores[day]['polarity'].append(polarity)\n",
    "    scores[day]['subjectivity'].append(subjectivity)\n",
    "    \n",
    "#calculate and display average polarity and subjectivity scores for all sentences\n",
    "for day,scores in scores.items():\n",
    "    polarity_scores = scores['polarity']\n",
    "    subjectivity_scores = scores['subjectivity']\n",
    "    print('Day:', day)\n",
    "    print('average polarity: {:.3f}'.format(np.mean(polarity_scores)))\n",
    "    print('average subjectivity: {:.3f}'.format(np.mean(subjectivity_scores)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the average scores on day basic and storing in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "\n",
    "#Calculating the polarity and aggregating with respect to day\n",
    "for index,row in tweets_df.iterrows():\n",
    "    day = row['day']\n",
    "    tweet = row['cleaned_tweets']\n",
    "    #the str() function is used to ensure that the input value is a string\n",
    "    blob = TextBlob(str(tweet))\n",
    "    #get polarity and subjectivity scores\n",
    "    polarity, subjectivity = blob.polarity, blob.subjectivity\n",
    "    if day not in scores:\n",
    "        scores[day] = {'polarity':[],'subjectivity':[]}\n",
    "    scores[day]['polarity'].append(polarity)\n",
    "    scores[day]['subjectivity'].append(subjectivity)\n",
    "\n",
    "# dataframe to store day and scores\n",
    "tweets_avg = pd.DataFrame(columns = ['day', 'Avg_Polarity', 'Avg_Subjectivity'])\n",
    "\n",
    "#calculate and display average polarity and subjectivity scores for all sentences\n",
    "for day,scores in scores.items():\n",
    "    polarity_scores = scores['polarity']\n",
    "    subjectivity_scores = scores['subjectivity']\n",
    "    average_polarity = np.mean(polarity_scores)\n",
    "    average_subjectivity = np.mean(subjectivity_scores)\n",
    "    tweets_avg = tweets_avg.append({'day': day, 'Avg_Polarity': average_polarity, 'Avg_Subjectivity': average_subjectivity}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_avg.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appending the average scores to numerical dataframe (sheet1 of given data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df['Avg_Polarity_score'] = tweets_avg['Avg_Polarity']\n",
    "price_df['Avg_Subjectivity_score'] =  tweets_avg['Avg_Subjectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dividing the rows based on empty cells in next_day_close_price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a dataframe containing only those rows for which\n",
    "#predictions for the next day’s closing price need to be made\n",
    "days_predict = price_df[pd.isnull(price_df.next_day_close_price) == True].copy()\n",
    "\n",
    "#remove all incomplete rows from the 'df' dataframe\n",
    "price_df = price_df[pd.isnull(price_df.next_day_close_price) == False].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df['next_day_close_price'].plot(xlabel = 'day', ylabel = 'next_day_close_price', \n",
    "                                      title = 'next_day_close_price VS day')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df.corr().style.format(\"{:.4}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_use = ['day', 'open_price', \n",
    "                   'high_price', \n",
    "                   'low_price', \n",
    "                   'volume',\n",
    "                   'moving_average_5_day',\n",
    "                   'moving_average_10_day',\n",
    "                   'moving_average_50_day',\n",
    "                   'moving_average_200_day', \n",
    "                   'next_day_close_price', \n",
    "                   'Avg_Polarity_score',\n",
    "                   'Avg_Subjectivity_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into training and testing sets\n",
    "df_train, df_test = train_test_split(price_df[features_to_use].copy(), train_size=0.7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the number of rows in the training set\n",
    "print(\"Count of rows in training data:\", len(df_train))\n",
    "\n",
    "#display the number of rows in the testing set\n",
    "print(\"Count of rows in testing data:\", len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_preds = ['day', 'open_price', 'high_price', \n",
    "                   'low_price', 'volume', \n",
    "               'Avg_Polarity_score',\n",
    "               'Avg_Subjectivity_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear ML\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "m1 = model.fit(df_train[Final_preds], df_train.next_day_close_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate predictions, and save them in a new column named \"Has_high_income\" in the testing dataframe\n",
    "df_test['lr_preds'] = m1.predict(df_test[Final_preds])\n",
    "\n",
    "#view actual and predicted values for the first 20 women in the testing set\n",
    "df_test[['next_day_close_price', 'lr_preds']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error\n",
    "mse = mean_squared_error(df_test['next_day_close_price'], df_test['lr_preds'])\n",
    "\n",
    "# Print the accuracy (MSE) score\n",
    "print('Accuracy (MSE):', mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the R-squared score\n",
    "r2 = r2_score(df_test['next_day_close_price'], df_test['lr_preds'])\n",
    "\n",
    "# Print the R-squared score\n",
    "print('R-squared score:', r2)\n",
    "\n",
    "mae = mean_absolute_error(df_test['next_day_close_price'], df_test['lr_preds'])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "m2 = rf.fit(df_train[Final_preds], df_train.next_day_close_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "df_test['rf_predictions'] = m2.predict(df_test[Final_preds])\n",
    "\n",
    "# Calculate the mean squared error\n",
    "rf_mse = mean_squared_error(df_test['next_day_close_price'], df_test['rf_predictions'])\n",
    "\n",
    "# Print the accuracy (MSE) score\n",
    "print('Accuracy (MSE):', rf_mse)\n",
    "\n",
    "mae = mean_absolute_error(df_test.next_day_close_price, df_test['rf_predictions'])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(df_test['next_day_close_price'], df_test['rf_predictions'])\n",
    "print('R-squared score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "rg = Ridge()\n",
    "m3 = rg.fit(df_train[Final_preds], df_train.next_day_close_price)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "df_test['rg_predictions'] = m3.predict(df_test[Final_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error\n",
    "rg_mse = mean_squared_error(df_test['next_day_close_price'], df_test['rg_predictions'])\n",
    "\n",
    "# Print the accuracy (MSE) score\n",
    "print('Accuracy (MSE):', rg_mse)\n",
    "\n",
    "mae = mean_absolute_error(df_test.next_day_close_price, df_test['rg_predictions'])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(df_test['next_day_close_price'], df_test['rg_predictions'])\n",
    "\n",
    "print('R-squared score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lr = Lasso()\n",
    "m4 = lr.fit(df_train[Final_preds], df_train.next_day_close_price)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "df_test['lr_predictions'] = m4.predict(df_test[Final_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean squared error\n",
    "lr_mse = mean_squared_error(df_test['next_day_close_price'], df_test['lr_predictions'])\n",
    "\n",
    "# Print the accuracy (MSE) score\n",
    "print('Accuracy (MSE):', lr_mse)\n",
    "\n",
    "mae = mean_absolute_error(df_test.next_day_close_price, df_test['lr_predictions'])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(df_test['next_day_close_price'], df_test['lr_predictions'])\n",
    "\n",
    "print('R-squared score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_model = SVR(kernel='poly', degree=2)\n",
    "m5 = svm_model.fit(df_train[Final_preds], df_train.next_day_close_price)\n",
    "\n",
    "df_test['svm_predictions'] = m5.predict(df_test[Final_preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the mean squared error\n",
    "svm_mse = mean_squared_error(df_test['next_day_close_price'], df_test['svm_predictions'])\n",
    "\n",
    "# Print the accuracy (MSE) score\n",
    "print('Accuracy (MSE):', svm_mse)\n",
    "\n",
    "mae = mean_absolute_error(df_test.next_day_close_price, df_test['svm_predictions'])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(df_test['next_day_close_price'], df_test['svm_predictions'])\n",
    "\n",
    "print('R-squared score:', r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Target Variable\n",
    "output_var = pd.DataFrame(price_df['next_day_close_price'])\n",
    "#Selecting the Features\n",
    "features = ['day', 'open_price', 'volume', 'Avg_Polarity_score',\n",
    "               'Avg_Subjectivity_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "feature_transform = scaler.fit_transform(price_df[features])\n",
    "feature_transform= pd.DataFrame(columns=features, data=feature_transform, index=price_df.index)\n",
    "feature_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "\n",
    "timesplit= TimeSeriesSplit(n_splits=10)\n",
    "for train_index, test_index in timesplit.split(feature_transform):\n",
    "        X_train, X_test = feature_transform[:len(train_index)], feature_transform[len(train_index): (len(train_index)+len(test_index))]\n",
    "        y_train, y_test = output_var[:len(train_index)].values.ravel(), output_var[len(train_index): (len(train_index)+len(test_index))].values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Process the data for LSTM\n",
    "trainX =np.array(X_train)\n",
    "testX =np.array(X_test)\n",
    "X_train = trainX.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "X_test = testX.reshape(X_test.shape[0], 1, X_test.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install keras\n",
    "#!pip install pydot\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show pydot\n",
    "!pip show graphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras. utils.vis_utils import plot_model\n",
    "import pydot\n",
    "import graphviz\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "#Building the LSTM Model\n",
    "lstm = Sequential()\n",
    "lstm.add(LSTM(32, input_shape=(1, trainX.shape[1]), activation='relu', return_sequences=False))\n",
    "lstm.add(Dense(1))\n",
    "lstm.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "history=lstm.fit(X_train, y_train, epochs=100, batch_size=8, verbose=1, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Prediction\n",
    "y_pred= lstm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted vs True Adj Close Value – LSTM\n",
    "plt.plot(y_test, label='True Value')\n",
    "plt.plot(y_pred, label='LSTM Value')\n",
    "plt.title(\"Prediction by LSTM\")\n",
    "plt.xlabel('Time Scale')\n",
    "plt.ylabel('Scaled USD')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred, squared = False)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --user pycaret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "s = setup(df_train, target = 'next_day_close_price',\n",
    "          #ignore_features = ['moving_average_200_day'], \n",
    "          session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict_model(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only few features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from pycaret.regression import *\n",
    "s2 = setup(df_train, target = 'next_day_close_price',\n",
    "          ignore_features = ['moving_average_5_day',\n",
    "                             'moving_average_10_day',\n",
    "                             'moving_average_50_day',\n",
    "                             'moving_average_200_day'], \n",
    "          session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_few_features = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_few_features)\n",
    "y_pred_few_features = predict_model(best_few_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from pycaret.regression import *\n",
    "s2 = setup(df_train, target = 'next_day_close_price',\n",
    "          ignore_features = ['moving_average_5_day',\n",
    "                             'moving_average_10_day',\n",
    "                             'moving_average_50_day',\n",
    "                             'moving_average_200_day'], normalize = True, session_id = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_few_features_normalized = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(best_few_features_normalized)\n",
    "y_pred_few_features_norm = predict_model(best_few_features_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set Target Variable\n",
    "output_var = pd.DataFrame(price_df['next_day_close_price'])\n",
    "\n",
    "#Selecting the Features\n",
    "features = ['day', 'open_price', 'high_price', \n",
    "                   'low_price', 'volume', \n",
    "               'Avg_Polarity_score',\n",
    "               'Avg_Subjectivity_score']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into training and testing sets\n",
    "#df_train, df_test = train_test_split(price_df[features].copy(), train_size=0.7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "price_df[features] = scaler.fit_transform(price_df[features])\n",
    "#feature_transform= pd.DataFrame(columns=features, data=feature_transform, index=price_df.index)\n",
    "#feature_transform.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into training and testing sets\n",
    "df_train, df_test = train_test_split(price_df.copy(), train_size=0.7, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>open_price</th>\n",
       "      <th>high_price</th>\n",
       "      <th>low_price</th>\n",
       "      <th>moving_average_5_day</th>\n",
       "      <th>moving_average_10_day</th>\n",
       "      <th>moving_average_50_day</th>\n",
       "      <th>moving_average_200_day</th>\n",
       "      <th>volume</th>\n",
       "      <th>next_day_close_price</th>\n",
       "      <th>Avg_Polarity_score</th>\n",
       "      <th>Avg_Subjectivity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>0.521522</td>\n",
       "      <td>0.235200</td>\n",
       "      <td>0.266133</td>\n",
       "      <td>0.253809</td>\n",
       "      <td>38.02</td>\n",
       "      <td>38.19</td>\n",
       "      <td>40.10</td>\n",
       "      <td>34.37</td>\n",
       "      <td>0.076469</td>\n",
       "      <td>39.84</td>\n",
       "      <td>0.550769</td>\n",
       "      <td>0.648599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>0.737738</td>\n",
       "      <td>0.258146</td>\n",
       "      <td>0.256751</td>\n",
       "      <td>0.271321</td>\n",
       "      <td>39.40</td>\n",
       "      <td>39.53</td>\n",
       "      <td>37.76</td>\n",
       "      <td>42.55</td>\n",
       "      <td>0.061983</td>\n",
       "      <td>39.91</td>\n",
       "      <td>0.400855</td>\n",
       "      <td>0.718709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.281781</td>\n",
       "      <td>0.284439</td>\n",
       "      <td>0.295884</td>\n",
       "      <td>39.18</td>\n",
       "      <td>39.43</td>\n",
       "      <td>37.77</td>\n",
       "      <td>42.56</td>\n",
       "      <td>0.048017</td>\n",
       "      <td>40.32</td>\n",
       "      <td>0.544441</td>\n",
       "      <td>0.618466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>0.660661</td>\n",
       "      <td>0.422671</td>\n",
       "      <td>0.415103</td>\n",
       "      <td>0.417330</td>\n",
       "      <td>46.51</td>\n",
       "      <td>46.55</td>\n",
       "      <td>47.34</td>\n",
       "      <td>42.53</td>\n",
       "      <td>0.081975</td>\n",
       "      <td>45.78</td>\n",
       "      <td>0.655835</td>\n",
       "      <td>0.706235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>0.411411</td>\n",
       "      <td>0.159477</td>\n",
       "      <td>0.156751</td>\n",
       "      <td>0.171708</td>\n",
       "      <td>33.55</td>\n",
       "      <td>33.16</td>\n",
       "      <td>31.86</td>\n",
       "      <td>31.57</td>\n",
       "      <td>0.085738</td>\n",
       "      <td>34.06</td>\n",
       "      <td>0.296035</td>\n",
       "      <td>0.172929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>0.468468</td>\n",
       "      <td>0.312299</td>\n",
       "      <td>0.333181</td>\n",
       "      <td>0.328633</td>\n",
       "      <td>40.22</td>\n",
       "      <td>38.50</td>\n",
       "      <td>34.41</td>\n",
       "      <td>31.76</td>\n",
       "      <td>0.115744</td>\n",
       "      <td>42.85</td>\n",
       "      <td>0.636535</td>\n",
       "      <td>0.707934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.935936</td>\n",
       "      <td>0.980725</td>\n",
       "      <td>0.971167</td>\n",
       "      <td>0.972026</td>\n",
       "      <td>64.91</td>\n",
       "      <td>62.63</td>\n",
       "      <td>60.50</td>\n",
       "      <td>49.73</td>\n",
       "      <td>0.125197</td>\n",
       "      <td>68.85</td>\n",
       "      <td>0.301197</td>\n",
       "      <td>0.325671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0.428428</td>\n",
       "      <td>0.053924</td>\n",
       "      <td>0.057208</td>\n",
       "      <td>0.069593</td>\n",
       "      <td>32.55</td>\n",
       "      <td>32.49</td>\n",
       "      <td>32.61</td>\n",
       "      <td>31.24</td>\n",
       "      <td>0.233782</td>\n",
       "      <td>31.98</td>\n",
       "      <td>0.560776</td>\n",
       "      <td>0.632741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.418082</td>\n",
       "      <td>0.418078</td>\n",
       "      <td>0.426882</td>\n",
       "      <td>45.18</td>\n",
       "      <td>44.87</td>\n",
       "      <td>40.87</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.129724</td>\n",
       "      <td>45.21</td>\n",
       "      <td>0.183858</td>\n",
       "      <td>0.567807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.155155</td>\n",
       "      <td>0.218449</td>\n",
       "      <td>0.213272</td>\n",
       "      <td>0.230839</td>\n",
       "      <td>37.34</td>\n",
       "      <td>37.52</td>\n",
       "      <td>38.48</td>\n",
       "      <td>40.46</td>\n",
       "      <td>0.030835</td>\n",
       "      <td>37.14</td>\n",
       "      <td>0.343502</td>\n",
       "      <td>0.591891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          day  open_price  high_price  low_price  moving_average_5_day  \\\n",
       "521  0.521522    0.235200    0.266133   0.253809                 38.02   \n",
       "737  0.737738    0.258146    0.256751   0.271321                 39.40   \n",
       "740  0.740741    0.281781    0.284439   0.295884                 39.18   \n",
       "660  0.660661    0.422671    0.415103   0.417330                 46.51   \n",
       "411  0.411411    0.159477    0.156751   0.171708                 33.55   \n",
       "..        ...         ...         ...        ...                   ...   \n",
       "468  0.468468    0.312299    0.333181   0.328633                 40.22   \n",
       "935  0.935936    0.980725    0.971167   0.972026                 64.91   \n",
       "428  0.428428    0.053924    0.057208   0.069593                 32.55   \n",
       "7    0.007007    0.418082    0.418078   0.426882                 45.18   \n",
       "155  0.155155    0.218449    0.213272   0.230839                 37.34   \n",
       "\n",
       "     moving_average_10_day  moving_average_50_day  moving_average_200_day  \\\n",
       "521                  38.19                  40.10                   34.37   \n",
       "737                  39.53                  37.76                   42.55   \n",
       "740                  39.43                  37.77                   42.56   \n",
       "660                  46.55                  47.34                   42.53   \n",
       "411                  33.16                  31.86                   31.57   \n",
       "..                     ...                    ...                     ...   \n",
       "468                  38.50                  34.41                   31.76   \n",
       "935                  62.63                  60.50                   49.73   \n",
       "428                  32.49                  32.61                   31.24   \n",
       "7                    44.87                  40.87                   42.31   \n",
       "155                  37.52                  38.48                   40.46   \n",
       "\n",
       "       volume  next_day_close_price  Avg_Polarity_score  \\\n",
       "521  0.076469                 39.84            0.550769   \n",
       "737  0.061983                 39.91            0.400855   \n",
       "740  0.048017                 40.32            0.544441   \n",
       "660  0.081975                 45.78            0.655835   \n",
       "411  0.085738                 34.06            0.296035   \n",
       "..        ...                   ...                 ...   \n",
       "468  0.115744                 42.85            0.636535   \n",
       "935  0.125197                 68.85            0.301197   \n",
       "428  0.233782                 31.98            0.560776   \n",
       "7    0.129724                 45.21            0.183858   \n",
       "155  0.030835                 37.14            0.343502   \n",
       "\n",
       "     Avg_Subjectivity_score  \n",
       "521                0.648599  \n",
       "737                0.718709  \n",
       "740                0.618466  \n",
       "660                0.706235  \n",
       "411                0.172929  \n",
       "..                      ...  \n",
       "468                0.707934  \n",
       "935                0.325671  \n",
       "428                0.632741  \n",
       "7                  0.567807  \n",
       "155                0.591891  \n",
       "\n",
       "[300 rows x 12 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear ML\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "model = LinearRegression()\n",
    "m1 = model.fit(df_train[features], df_train.next_day_close_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next_day_close_price</th>\n",
       "      <th>lr2_preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>39.84</td>\n",
       "      <td>39.345142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737</th>\n",
       "      <td>39.91</td>\n",
       "      <td>38.916817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>40.32</td>\n",
       "      <td>40.335369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>45.78</td>\n",
       "      <td>45.776515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>34.06</td>\n",
       "      <td>34.086399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>44.42</td>\n",
       "      <td>45.554047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>626</th>\n",
       "      <td>48.92</td>\n",
       "      <td>48.487892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>37.33</td>\n",
       "      <td>37.771480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>46.09</td>\n",
       "      <td>45.554055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>37.71</td>\n",
       "      <td>37.778709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>44.25</td>\n",
       "      <td>44.472021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>38.36</td>\n",
       "      <td>38.152387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>48.22</td>\n",
       "      <td>49.013984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>62.65</td>\n",
       "      <td>62.505314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>68.76</td>\n",
       "      <td>68.845805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>60.00</td>\n",
       "      <td>58.708933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>30.05</td>\n",
       "      <td>30.261381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>59.92</td>\n",
       "      <td>59.263660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>42.65</td>\n",
       "      <td>43.081328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>30.50</td>\n",
       "      <td>31.018978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>40.19</td>\n",
       "      <td>40.414009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>39.29</td>\n",
       "      <td>39.465677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>30.00</td>\n",
       "      <td>30.297868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>39.34</td>\n",
       "      <td>39.381725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>39.29</td>\n",
       "      <td>38.842437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>36.11</td>\n",
       "      <td>36.259797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>40.75</td>\n",
       "      <td>41.427639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>64.34</td>\n",
       "      <td>63.331672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>60.70</td>\n",
       "      <td>60.236877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>947</th>\n",
       "      <td>70.14</td>\n",
       "      <td>68.920217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>30.30</td>\n",
       "      <td>30.550470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>37.56</td>\n",
       "      <td>37.093942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>47.63</td>\n",
       "      <td>47.811031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>41.33</td>\n",
       "      <td>41.045073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>29.94</td>\n",
       "      <td>29.761964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>42.71</td>\n",
       "      <td>43.035865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>39.14</td>\n",
       "      <td>38.445429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>42.10</td>\n",
       "      <td>41.949342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>59.69</td>\n",
       "      <td>59.439868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>37.76</td>\n",
       "      <td>37.712309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     next_day_close_price  lr2_preds\n",
       "521                 39.84  39.345142\n",
       "737                 39.91  38.916817\n",
       "740                 40.32  40.335369\n",
       "660                 45.78  45.776515\n",
       "411                 34.06  34.086399\n",
       "678                 44.42  45.554047\n",
       "626                 48.92  48.487892\n",
       "513                 37.33  37.771480\n",
       "859                 46.09  45.554055\n",
       "136                 37.71  37.778709\n",
       "811                 44.25  44.472021\n",
       "76                  38.36  38.152387\n",
       "636                 48.22  49.013984\n",
       "973                 62.65  62.505314\n",
       "938                 68.76  68.845805\n",
       "899                 60.00  58.708933\n",
       "280                 30.05  30.261381\n",
       "883                 59.92  59.263660\n",
       "761                 42.65  43.081328\n",
       "319                 30.50  31.018978\n",
       "549                 40.19  40.414009\n",
       "174                 39.29  39.465677\n",
       "371                 30.00  30.297868\n",
       "527                 39.34  39.381725\n",
       "210                 39.29  38.842437\n",
       "235                 36.11  36.259797\n",
       "101                 40.75  41.427639\n",
       "986                 64.34  63.331672\n",
       "902                 60.70  60.236877\n",
       "947                 70.14  68.920217\n",
       "346                 30.30  30.550470\n",
       "139                 37.56  37.093942\n",
       "621                 47.63  47.811031\n",
       "499                 41.33  41.045073\n",
       "370                 29.94  29.761964\n",
       "198                 42.71  43.035865\n",
       "687                 39.14  38.445429\n",
       "584                 42.10  41.949342\n",
       "901                 59.69  59.439868\n",
       "59                  37.76  37.712309"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#generate predictions, and save them in a new column named \"Has_high_income\" in the testing dataframe\n",
    "df_test['lr2_preds'] = m1.predict(df_test[features])\n",
    "\n",
    "#view actual and predicted values for the first 20 women in the testing set\n",
    "df_test[['next_day_close_price', 'lr2_preds']].head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (MSE): 0.5581274576119781\n",
      "Mean Absolute Error (MAE): 0.4080711713595214\n",
      "R-squared score: 0.9946622477914075\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error\n",
    "lr2_mse = mean_squared_error(df_test['next_day_close_price'], df_test['lr2_preds'])\n",
    "\n",
    "# Print the accuracy (MSE) score\n",
    "print('Accuracy (MSE):', lr2_mse)\n",
    "\n",
    "mae = mean_absolute_error(df_test.next_day_close_price, df_test['lr2_preds'])\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "# Calculate the R-squared score\n",
    "r2 = r2_score(df_test['next_day_close_price'], df_test['lr2_preds'])\n",
    "\n",
    "print('R-squared score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_predict['predicted_day_close_price'] =  m1.predict(days_predict[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_predict[['day', 'predicted_day_close_price']].to_csv('result.csv', columns = ['day', 'predicted_day_close_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test[['next_day_close_price', 'Pred_next_day_close_price']].to_csv('checking.csv', columns = ['day', next_day_close_price', 'Pred_next_day_close_price'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
